{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4de9adc3",
   "metadata": {},
   "source": [
    "## Install and import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c7fe8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in d:\\python\\lib\\site-packages (0.10.9)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: matplotlib in d:\\python\\lib\\site-packages (from mediapipe) (3.7.0)\n",
      "Requirement already satisfied: numpy in d:\\python\\lib\\site-packages (from mediapipe) (1.23.5)\n",
      "Requirement already satisfied: absl-py in d:\\python\\lib\\site-packages (from mediapipe) (2.0.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in d:\\python\\lib\\site-packages (from mediapipe) (23.5.26)\n",
      "Requirement already satisfied: opencv-contrib-python in d:\\python\\lib\\site-packages (from mediapipe) (4.8.1.78)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in d:\\python\\lib\\site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: attrs>=19.1.0 in d:\\python\\lib\\site-packages (from mediapipe) (22.1.0)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in d:\\python\\lib\\site-packages (from mediapipe) (0.4.6)\n",
      "Requirement already satisfied: CFFI>=1.0 in d:\\python\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\python\\lib\\site-packages (from matplotlib->mediapipe) (9.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\python\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\python\\lib\\site-packages (from matplotlib->mediapipe) (4.25.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\python\\lib\\site-packages (from matplotlib->mediapipe) (1.0.5)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\python\\lib\\site-packages (from matplotlib->mediapipe) (22.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in d:\\python\\lib\\site-packages (from matplotlib->mediapipe) (5.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\python\\lib\\site-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\python\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\python\\lib\\site-packages (from matplotlib->mediapipe) (1.4.4)\n",
      "Requirement already satisfied: pycparser in d:\\python\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: zipp>=3.1.0 in d:\\python\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->mediapipe) (3.11.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\python\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: opencv-python in d:\\python\\lib\\site-packages (4.8.1.78)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy>=1.17.3 in d:\\python\\lib\\site-packages (from opencv-python) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d699e651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cac0de",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b6f24e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=False,\n",
    "    max_num_faces=1,\n",
    "    min_detection_confidence=0.6,\n",
    "    min_tracking_confidence=0.6\n",
    ")\n",
    "\n",
    "# For accessing the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# I defined facial features indices by hand for better precision.\n",
    "# MediaPipe uses a total of 468 indice points in face to create a mesh. You can see the map from this link:\n",
    "# https://github.com/google/mediapipe/blob/a908d668c730da128dfa8d9f6bd25d519d006692/mediapipe/modules/face_geometry/data/canonical_face_model_uv_visualization.png\n",
    "\n",
    "left_eye_indices = list((359,467,260,259,257,258,286,414,463,341,256,252,253,254,339,255))\n",
    "right_eye_indices = list((130,25,110,24,23,22,26,112,243,190,56,28,27,29,30,247))\n",
    "nose_indices = list((168,417,413,414,382,341,453,357,343,437,420,360,344,438,309,250,462,370,94,\n",
    "                    141,242,20,79,218,115,131,198,217,114,128,233,112,155,173,190,189,193))\n",
    "upper_lip_indices = list((61,185,40,39,37,0,267,269,270,409,291,308,415,310,311,312,13,82,81,80,191,78,62,76))\n",
    "lower_lip_indices = list((61,146,91,181,84,17,314,405,321,375,291,308,324,318,402,317,14,87,179,88,95,78,62,76))\n",
    "\n",
    "mouth_area = [78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95]\n",
    "\n",
    "# For talking detection\n",
    "prev_area = None\n",
    "\n",
    "start_time = None\n",
    "display_duration = 1\n",
    "\n",
    "\n",
    "facial_features = {\n",
    "    \"left_eye\": left_eye_indices,\n",
    "    \"right_eye\": right_eye_indices,\n",
    "    \"nose\": nose_indices,\n",
    "    \"upper_lip\": upper_lip_indices,\n",
    "    \"lower_lip\": lower_lip_indices\n",
    "}\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Failed to capture frame\")\n",
    "        break\n",
    "\n",
    "    # I am resizing the frame beacuse the code have a threshold in a distance calculation down below. Distances change with cam \n",
    "    # resolutions so a standard size is needed. I also wanted to improve performance by choosing a rather low resolution\n",
    "    frame = cv2.resize(frame, (640, 480))    \n",
    "        \n",
    "    # I converted the frame from BGR to RGB. \n",
    "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results = face_mesh.process(image_rgb)\n",
    "\n",
    "    # I grouped corresponding facial landmarks\n",
    "    facial_landmarks = {\"left_eye\": [], \"right_eye\": [], \"nose\": [], \"upper_lip\": [], \"lower_lip\":[]}\n",
    "    if results.multi_face_landmarks:\n",
    "        \n",
    "        landmarks = results.multi_face_landmarks[0] \n",
    "        \n",
    "        # I wanted to calculate the eye distance. Eye distance (or pupilary distance) is calculated from pupil to pupil\n",
    "        # Since there is not an indice for pupils in the map, I calculated the distance from upper middle point and\n",
    "        # the lower middle point of the eyes, then measuered the distance between them.\n",
    "        \n",
    "        # Got the coordinates\n",
    "        landmark_159 = (int(landmarks.landmark[159].x * frame.shape[1]),\n",
    "                        int(landmarks.landmark[159].y * frame.shape[0]))\n",
    "\n",
    "        landmark_145 = (int(landmarks.landmark[145].x * frame.shape[1]),\n",
    "                        int(landmarks.landmark[145].y * frame.shape[0]))\n",
    "\n",
    "        landmark_386 = (int(landmarks.landmark[386].x * frame.shape[1]),\n",
    "                        int(landmarks.landmark[386].y * frame.shape[0]))\n",
    "\n",
    "        landmark_374 = (int(landmarks.landmark[374].x * frame.shape[1]),\n",
    "                        int(landmarks.landmark[374].y * frame.shape[0]))\n",
    "\n",
    "        # Calculated the middle points\n",
    "        middle_point_159_145 = ((landmark_159[0] + landmark_145[0]) // 2, (landmark_159[1] + landmark_145[1]) // 2)\n",
    "        middle_point_386_374 = ((landmark_386[0] + landmark_374[0]) // 2, (landmark_386[1] + landmark_374[1]) // 2)\n",
    "\n",
    "        # Finally I calculated the euclidean distance between those points\n",
    "        distance = np.linalg.norm(np.array(middle_point_159_145) - np.array(middle_point_386_374))\n",
    "\n",
    "        \n",
    "        # Code below basically calculates the distance from middle upper indices of the eyes to middle indice of the eyebrows.\n",
    "        # If their sum is high enough, a text appears telling you that you are surprised.\n",
    "        \n",
    "        landmark_282 = (int(landmarks.landmark[282].x * frame.shape[1]),\n",
    "                        int(landmarks.landmark[282].y * frame.shape[0]))\n",
    "\n",
    "        landmark_257 = (int(landmarks.landmark[257].x * frame.shape[1]),\n",
    "                        int(landmarks.landmark[257].y * frame.shape[0]))\n",
    "\n",
    "        landmark_27 = (int(landmarks.landmark[27].x * frame.shape[1]),\n",
    "                       int(landmarks.landmark[27].y * frame.shape[0]))\n",
    "\n",
    "        landmark_52 = (int(landmarks.landmark[52].x * frame.shape[1]),\n",
    "                       int(landmarks.landmark[52].y * frame.shape[0]))\n",
    "\n",
    "        # Calculated the distances\n",
    "        distance_282_257 = np.linalg.norm(np.array(landmark_282) - np.array(landmark_257))\n",
    "        distance_27_52 = np.linalg.norm(np.array(landmark_27) - np.array(landmark_52))\n",
    "        \n",
    "        \n",
    "        # Detecting facial features \n",
    "        for feature, indices in facial_features.items():\n",
    "            facial_landmarks[feature] = [(int(landmarks.landmark[idx].x * frame.shape[1]),\n",
    "                                          int(landmarks.landmark[idx].y * frame.shape[0]))\n",
    "                                         for idx in indices]\n",
    "\n",
    "        \n",
    "        for feature, landmarks_list in facial_landmarks.items():\n",
    "            cv2.polylines(frame, [np.array(landmarks_list)], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "            centroid = np.mean(landmarks_list, axis=0, dtype=int)\n",
    "            # It writes the corresponding facial feature on the lines.\n",
    "            cv2.putText(frame, feature, (centroid[0], centroid[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2,\n",
    "                        cv2.LINE_AA)\n",
    "            \n",
    "            # Text for pupillary distance\n",
    "            cv2.putText(frame, f\"Pupillary distance is: {distance:.2f}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            # I also wanted to see the distance as a line in real time\n",
    "            cv2.line(frame, middle_point_159_145, middle_point_386_374, (255, 0, 0), 2)\n",
    "\n",
    "            # Pupillary distance determines the distance from the camera. I proportioned the eyebrow distance to pupillary distance so the code works on all webcam distances\n",
    "            # I also multiplied the pupillary distance by two, because since we have two eyebrow distances, they increase or decrease by 2x, while pupillary distance changes by x\n",
    "            if (distance_282_257 + distance_27_52)/ (distance*2) > 0.25:\n",
    "                cv2.putText(frame, \"You are SURPRISED!\", (10, 60),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Calculating the mouth area\n",
    "            polygon_vertices = [(int(landmarks.landmark[idx].x * frame.shape[1]),\n",
    "                                 int(landmarks.landmark[idx].y * frame.shape[0]))\n",
    "                                for idx in mouth_area]\n",
    "\n",
    "            area = 0.5 * np.abs(sum(x0 * y1 - x1 * y0 for (x0, y0), (x1, y1) in zip(polygon_vertices, polygon_vertices[1:] + [polygon_vertices[0]])))\n",
    "\n",
    "            # If the mouth area changes in proportion to the camera distance, a text appears to tell you that you are talking.\n",
    "            if prev_area is not None:\n",
    "                area_difference = area - prev_area\n",
    "                \n",
    "                if area_difference/distance > 1.5 :\n",
    "                    cv2.putText(frame, \"You are talking.\", (10, 90),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                    start_time = time.time()  # Reset the timer\n",
    "                elif start_time is not None and time.time() - start_time < display_duration:\n",
    "                    cv2.putText(frame, \"You are talking.\", (10, 90),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Update the previous area\n",
    "            prev_area = area\n",
    "                      \n",
    "    cv2.imshow('Facial Detection made by ali0onder', frame)\n",
    "\n",
    "    # Will close the camera if \"ESC\" button is pressed\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2366463a",
   "metadata": {},
   "source": [
    "## If you don't want to include eyelids while detecting eyes, use these coordinates instead:\n",
    "right eye = (7,33,163,144,145,153,154,155,133,173,157,158,159,160,161,246)\n",
    "\n",
    "left eye = (263,466,388,387,386,385,384,398,362,382,381,380,374,373,390,249)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
